# Case
I had promised myself to learn web-scraping as part of my learning progression in my previous projects. I am very happy to say that I have done my first scraping project and learnt so much, despite the frustration (as usual)


### **What do I want to learn?**
Youtube, Stackoverflow and many other websites have given me introductory web-scraping preview, though easy to follow, does not reflect the modern website structure.

These websites shown were mostly static, not updated and have a simple structure, when applied to read world websites with dynamic javascript built website and the doomed 'infinite scrolling' we now see, especially on social media, these methods are sure to fail.

Throughout my learning progress I have gather much needed information through Youtube, Stackoverflow and ChatGPT. The latter has helped me a lot to understand code structure and the logic flow of each line of code. It has improved my knowledge immensely.

<br>

### **Slowly learning the structure of HTML**
Very quickly I learnt that knowing the libraries only tells me how to use the library, it does not however teach me how to read HTML, which is of course required because the elements are hidden within. I had to put everything behind for the time being and learn some HTML tags, attributes, classes, tables and more.

<br>

### **Start scraping**
With some elementary knowledge about HTML structure I start my scraping practice, only to face another road-block because the library I know at that time (BeautifulSoup) a popular library is not very useful to scrape a dynamic webpage. After some googling selenium came up and now I have to learn that library instead. 

These patterns of road-blocks and troubleshooting pops up every once in a while, for which I have spent a lot of time but also grateful knowing the hows and whys to make it work.

<br>

### **Finally start scraping (maybe?)**
Using selenium itself is quite a joy for automation. As usual more obstacle pops up, bypassing verification, clicking on buttons, formatting extracted elements, simulate scrolling are all frustrating but great experiences. You can find it further within the code.

<br>

### **Data cleaning/manipulation**
Extracted elements are converted to a dataframe for easy manipulation and formatting. The final result are exported as a csv file.
